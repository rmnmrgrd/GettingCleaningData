Code book
=========

# Variables

## Original data set

## Tidy dataset

# Data

Two datasets are generated by this script:

1. `tidy_dataset`: A tidy dataset which includes the following columns:
  * `activity`: a factor containing the type of activity measured,
  * `subject`: integer assigned to the subject whose activity was measured,
  * `measure`: type of measure taken,
  * `value`: value of the measure taken.
  
2. `tidy_dataset_avg`: A tidy dataset which inclues the following columns:
  * `activity`: a factor containing the type of activity measured,
  * `subject`: integer assigned to the subject whose activity was measured,
  * `avg`: doble containing the average of all measures for that activit and subject.
  


After all the transofmrations described in the chapter below, the following variables are defined Which variables were kept

# Transformations

In order to build the tidy dataset, the following transformations have been executed

1. The activity labels have been loaded from file `activity_labels.txt`. This allows for giving understandable values to the activities,
2. Similarly, the features are loaded from file `features.txt`. This allows for correct identification of the features being measured,
3. The test and train data are read from files `dataset\test\X_test.txt` and `dataset\train\X_train.txt` respectively. Both datasets are merged into a single one by using rbind(),
4. Similarly, the activities for all measures are read from files `dataset\test\Y_test.txt` and `dataset\train\Y_train.txt`. Both datasets are merged into a singoe one by using rbind(),
5. Also, information about the subjects is loaded from file `dataset\\test\\subject_test.txt` and `dataset\train\subject_train.txt`. Both datasets are merged into a single one by using rbind().
6. The full dataset is built, using cbind(), by merging the activities, the subjects, and the test and train data,
7. The column names of the full dataset are set as `activity`, `subject` and each of the features. This gives a very wide dataset and that includes columns with duplicate values; in order to resolve the duplication, all column names are appended an integer number which is the column index. This is a temporary measure that is later cleaned up.
8. The desired measures (mean and std) are extracted from the full dataset by means of regular expressions; `activity` and `subject` are also included; this is stored in `tidy_dataset`, which after this step contains 68 columns,
9. As the column names are now not duplicated, the sequence number which was added in step 7 can now be removed; this is achieved by means of regular expressions and the `gsub()` function;
10. The 'activity' column in the `tidy_dataset` is substituted with the activity label instead of the activity code,
11. Using `gather()`, the 66 variables are mapped to key-value pairs, which provides a narrower and longer (i.e. tidier) dataset. This is stored in dataset 'tidy_dataset',
12. Finally, using group_by() and summarise(), the average of all measures per activity and subject is calculated and stored in `tidy_dataset_avg`.



code book that describes the variables, the data, and any transformations or work that you performed to clean up the data called CodeBook.md. You should also include a README.md in the repo with your scripts. This repo explains how all of the scripts work and how they are connected.